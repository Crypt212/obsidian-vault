- **Theory of Computation** is a branch of computer science and mathematics concerned with understanding the limitations of computing machines.
- **Computation** is the process of performing calculations or solving problems through a series of well-defined steps (IE, an algorithm).
# Importance of Computation theory
- **Defining limits of *Computation***: helps to avoid wasting resources (time, memory ... etc) on problems unsolvable by *Computation*.
- **Optimizing Algorithms Efficiency**: *Complexity Theory* categorizes problems based on resources needed to solve it (P, NP, NP-hard, NP-complete), providing guidance to decide whether to seek exact solutions or focus on approximations.
- **Enabling Practical Software and System Designs**: *Automata Theory* is foundational in designing programming languages and compilers and allows the creation of more reliable and optimized software systems.
- **Strengthening Cryptography and Security**: Understanding the limits of computation can help in designing secure and hard-to-break encryption systems.
- **Guiding Innovation in Emerging Technologies**: Helps defining the capabilities and limitations of new emerging computational models (like quantum computing), allowing us to design new algorithms that leverage these computational models, pushing the boundaries of what is possible.
# Languages and Grammars
- **Alphabet**: is a set of symbols. In *Automata Theory*, it represents the set of inputs.
- **String**: a finite concatenation of elements from the **Alphabet**. In *Automata Theory*, it represents the sequence of inputs.
- **Formal Language**: a set of all **strings** that could be generated over an **alphabet** using rules of **Grammar**.
- **Regular Language**: formal languages recognized by finite automata and described using regular expressions.
- **Context-Free Language**: formal languages that can be generated by context-free grammars and are recognized by pushdown automata (they require memory and recursive calls, which regular languages can't handle).
- **Grammar**: a set of production rules that define how strings in a language are formed.
- **Pumping Lemma for Regular Languages**: this is used to prove that a given
language is not regular. It provides a property that all regular language must satisfy, and if a language does not satisfy this, it is not regular.
- **Pumping Lemma for Context-Free Languages**: similar to the regular pumping lemma, this is used to show that a language is not context-free.
- **Turing Machine**: an abstract mathematical model of computation that manipulates symbols on infinite tape according to a set of rules.
- **Decidability**: whether a problem can be solved using a turing machine that will halt and provide a correct answer for all inputs.
## Example
- - **Context-Free Grammar for balanced parentheses:**
	- Alphabet: Σ = { `(`, `)` }
	- Variables: { `S` }
	- Start Symbol: `S`
	- Production Rules (Grammar):
		1. `S -> ( S )` (A balanced thing can be inside parentheses)
		2. `S -> S S` (Two balanced things in a row are balanced)
		3. `S -> ε` (An empty string is balanced)
	- Using these rules, you can generate `"()(())"` by starting with `S` and applying the rules.
	- S

## Operations on Languages
- Languages can be combined and manipulated using various operations:
- **Union ($L1 ∪ L2$)**: All strings in either $L1$ or $L2$.
- **Concatenation ($L1 · L2$)**: All strings formed by concatenating a string from $L1$ with a string from $L2$.
- **Kleene Star ($L^*$)**: All strings formed by concatenating zero or more strings from $L$.
- **Intersection ($L1 ∩ L2$)**: All strings that are in both $L1$ and $L2$.
# Finite Representation of Language
- Refers to the method of depicting a language (infinite set of strings) in a compact and precise way with finite structure.
- **WHY?** Because, while languages can b